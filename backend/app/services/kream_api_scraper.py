"""
KREAM API í¬ë¡¤ëŸ¬ - API ì§ì ‘ í˜¸ì¶œ ë°©ì‹
Playwright ëŒ€ì‹  APIë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ë´‡ ì°¨ë‹¨ì„ ìš°íšŒí•©ë‹ˆë‹¤.
"""

import httpx
import time
import logging
from typing import List, Dict, Optional
from datetime import datetime
from pathlib import Path
import uuid
import aiofiles
import hashlib

logger = logging.getLogger(__name__)


class KreamAPIScraper:
    """KREAM API ì§ì ‘ í˜¸ì¶œ í¬ë¡¤ëŸ¬"""

    def __init__(self):
        self.base_url = "https://api.kream.co.kr"
        self.device_id = f"web;{uuid.uuid4()}"

    def _get_headers(self) -> dict:
        """KREAM API í˜¸ì¶œì— í•„ìš”í•œ í—¤ë” ìƒì„±"""
        now = datetime.now().strftime("%Y%m%d%H%M%S%z")
        if not now.endswith("+0900"):
            now = now[:-2] + "+0900"

        return {
            "accept": "*/*",
            "accept-language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
            "cache-control": "no-cache",
            "origin": "https://kream.co.kr",
            "referer": "https://kream.co.kr/",
            "sec-ch-ua": '"Google Chrome";v="141", "Not?A_Brand";v="8", "Chromium";v="141"',
            "sec-ch-ua-mobile": "?0",
            "sec-ch-ua-platform": '"Windows"',
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-site",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36",
            "x-kream-api-version": "50",
            "x-kream-client-datetime": now,
            "x-kream-device-id": self.device_id,
            "x-kream-web-build-version": "25.13.4",
            "x-kream-web-request-secret": "kream-djscjsghdkd",
        }

    async def search_products(self, keyword: str, max_products: int = 100, page: int = 1) -> List[Dict]:
        """
        KREAM APIë¡œ ìƒí’ˆ ê²€ìƒ‰ (ìµœëŒ€í•œ ë§ì´ ê°€ì ¸ì˜¤ê¸°)

        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            max_products: ìµœëŒ€ ìƒí’ˆ ìˆ˜ (í˜ì´ì§€ë‹¹, ê¸°ë³¸ 100ê°œ - API ìµœëŒ€ì¹˜)
            page: í˜ì´ì§€ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)

        Returns:
            ìƒí’ˆ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        try:
            start_time = time.time()
            print(f"â±ï¸ [API] KREAM API ê²€ìƒ‰ ì‹œì‘: {keyword} (í˜ì´ì§€: {page}, ìš”ì²­: {max_products}ê°œ)")

            url = f"{self.base_url}/api/screens/search/products"
            params = {
                "keyword": keyword,
                "tab": "products",
                "typed_string": keyword,
                "search_type": "direct",
                "per_page": max_products,  # API ìµœëŒ€ê°’ ìš”ì²­
                "page": page,
            }

            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(
                    url,
                    params=params,
                    headers=self._get_headers()
                )

                print(f"ğŸ“¡ [API] ì‘ë‹µ ìƒíƒœ: {response.status_code}")

                if response.status_code != 200:
                    print(f"âŒ [API] API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}")
                    print(f"ì‘ë‹µ ë‚´ìš©: {response.text[:500]}")
                    return []

                data = response.json()
                print(f"âœ… [API] API ì‘ë‹µ ì„±ê³µ ({time.time() - start_time:.2f}ì´ˆ)")

                # ì‘ë‹µ êµ¬ì¡° í™•ì¸ (ë””ë²„ê¹…)
                print(f"ğŸ“¦ [API] ì‘ë‹µ í‚¤ ëª©ë¡: {list(data.keys())}")

                # ì „ì²´ ì‘ë‹µì„ íŒŒì¼ë¡œ ì €ì¥
                import json
                response_file = "/tmp/kream_api_response.json"
                with open(response_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
                print(f"ğŸ“¦ [API] ì „ì²´ ì‘ë‹µ ì €ì¥: {response_file}")

                # content êµ¬ì¡° í™•ì¸
                if "content" in data:
                    print(f"ğŸ“¦ [API] content í‚¤ ëª©ë¡: {list(data['content'].keys())}")
                    if "items" in data['content']:
                        print(f"ğŸ“¦ [API] items ê°œìˆ˜: {len(data['content']['items'])}")
                        # ì²« ë²ˆì§¸ itemì˜ items í™•ì¸ (ì¤‘ì²© êµ¬ì¡°)
                        if data['content']['items']:
                            first_item = data['content']['items'][0]
                            if "items" in first_item and first_item['items']:
                                inner_item = first_item['items'][0]
                                print(f"ğŸ“¦ [API] ì²« ë²ˆì§¸ inner item í‚¤: {list(inner_item.keys())}")
                                print(f"ğŸ“¦ [API] ì²« ë²ˆì§¸ inner item: {json.dumps(inner_item, indent=2, ensure_ascii=False)[:1500]}")

                # ì‘ë‹µ êµ¬ì¡° ë¶„ì„ - display_typeì´ 'product'ì¸ í•­ëª© ì¶”ì¶œ
                products = []
                seen_product_ids = set()  # ì¤‘ë³µ ë°©ì§€ìš©

                def extract_products(obj, depth=0):
                    """ì¬ê·€ì ìœ¼ë¡œ ìƒí’ˆ ê°ì²´ ì°¾ê¸°"""
                    if depth > 10 or len(products) >= max_products:
                        return

                    if isinstance(obj, dict):
                        # display_typeì´ 'product'ë¥¼ í¬í•¨í•˜ëŠ” ê²½ìš°
                        if 'display_type' in obj and 'product' in str(obj.get('display_type', '')).lower():
                            product_info = self._parse_product(obj)
                            # ì¤‘ë³µ ì²´í¬: product_idë¡œ í™•ì¸
                            if product_info and product_info.get('product_id'):
                                product_id = product_info['product_id']
                                if product_id not in seen_product_ids and len(products) < max_products:
                                    seen_product_ids.add(product_id)
                                    products.append(product_info)
                                    return  # ìƒí’ˆ ì°¾ì•˜ìœ¼ë©´ ë” ê¹Šì´ íƒìƒ‰í•˜ì§€ ì•ŠìŒ

                        # ì¬ê·€ íƒìƒ‰
                        for value in obj.values():
                            extract_products(value, depth + 1)

                    elif isinstance(obj, list):
                        for item in obj:
                            extract_products(item, depth + 1)

                extract_products(data)
                print(f"ğŸ” [API] íŒŒì‹±ëœ ìƒí’ˆ ìˆ˜: {len(products)}ê°œ (ì¤‘ë³µ ì œê±° í›„)")

                return products

        except Exception as e:
            logger.error(f"âŒ API ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return []

    def _parse_product(self, item: dict) -> Optional[Dict]:
        """API ì‘ë‹µì—ì„œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ"""
        try:
            # actionsì—ì„œ click_product ì´ë²¤íŠ¸ ì°¾ê¸°
            product_info = None
            image_url = None

            if 'actions' in item:
                for action in item['actions']:
                    # ìƒí’ˆ ì •ë³´ ì¶”ì¶œ (event_logì˜ propertiesì—ì„œ)
                    if action.get('value') == 'click_product':
                        props = action.get('parameters', {}).get('properties', [])
                        if props and len(props) > 0:
                            import json
                            product_info = json.loads(props[0])

                            # ì›ë³¸ API JSON ì „ì²´ ì¶œë ¥
                            print(f"\n{'='*80}")
                            print(f"ğŸ” API ì›ë³¸ JSON (ì „ì²´):")
                            print(f"{'='*80}")
                            print(json.dumps(product_info, indent=2, ensure_ascii=False))
                            print(f"{'='*80}\n")

            # itemsì—ì„œ ì´ë¯¸ì§€ URL ì°¾ê¸°
            if 'items' in item:
                for sub_item in item['items']:
                    if 'image_item' in sub_item:
                        img_elem = sub_item['image_item'].get('image_element', {})
                        if 'variations' in img_elem and img_elem['variations']:
                            # variations[0]ì— ì§ì ‘ urlì´ ìˆìŒ
                            var = img_elem['variations'][0]
                            if 'url' in var:
                                image_url = var['url']
                                break
                    if image_url:
                        break

            # ìƒí’ˆ ì •ë³´ê°€ ì—†ìœ¼ë©´ None ë°˜í™˜
            if not product_info:
                return None

            # ìƒ‰ìƒ ì¶”ì¶œ
            extracted_color = self._extract_color_from_name(product_info.get('product_name_en', ''))

            # ê²°ê³¼ êµ¬ì¡° ìƒì„±
            product_data = {
                'product_id': str(product_info.get('product_id', '')),
                'product_name_ko': product_info.get('product_name_ko', ''),
                'product_name_en': product_info.get('product_name_en', ''),
                'model_number': product_info.get('product_style_code', ''),
                'brand': product_info.get('brand_name', ''),
                'color': extracted_color,
                'release_price': product_info.get('price'),
                'image_url': image_url or '',
                'source_url': f"https://kream.co.kr/products/{product_info.get('product_id', '')}",
                'category_1d': product_info.get('shop_category_name_1d', ''),
                'category_2d': product_info.get('shop_category_name_2d', ''),
            }

            # ë””ë²„ê¹… ë¡œê·¸ (ì½˜ì†” ì¶œë ¥)
            print(f"\nğŸ“¦ íŒŒì‹± ì™„ë£Œ: {product_data['product_name_ko']}")
            print(f"   í’ˆë²ˆ: {product_data['model_number']}, ë¸Œëœë“œ: {product_data['brand']}")
            print(f"   ì¹´í…Œê³ ë¦¬: {product_data['category_1d']} > {product_data['category_2d']}")
            print(f"   ìƒ‰ìƒ: '{extracted_color}' (ì˜ë¬¸ëª…: {product_info.get('product_name_en', '')})")
            print(f"   ê°€ê²©: {product_data['release_price']}ì›")
            print(f"   ì´ë¯¸ì§€ URL: {image_url[:80] if image_url else 'None'}...")

            return product_data

        except Exception as e:
            logger.error(f"ìƒí’ˆ íŒŒì‹± ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _extract_color_from_name(self, name: str) -> str:
        """ìƒí’ˆëª…ì—ì„œ ìƒ‰ìƒ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)"""
        if not name:
            return ""

        # ì¼ë°˜ì ì¸ ìƒ‰ìƒ í‚¤ì›Œë“œ
        colors = ['Black', 'White', 'Red', 'Blue', 'Green', 'Yellow', 'Orange', 'Purple', 'Pink', 'Brown', 'Grey', 'Gray', 'Navy', 'Beige']

        found_colors = []
        name_upper = name.upper()

        for color in colors:
            if color.upper() in name_upper:
                found_colors.append(color)

        return ' '.join(found_colors) if found_colors else ""

    async def download_image(self, image_url: str, brand_name: str, model_number: str) -> str:
        """
        ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ë¡œì»¬ ê²½ë¡œ ë°˜í™˜

        Args:
            image_url: ì´ë¯¸ì§€ URL
            brand_name: ë¸Œëœë“œëª…
            model_number: ëª¨ë¸ë²ˆí˜¸

        Returns:
            ë¡œì»¬ ì´ë¯¸ì§€ ê²½ë¡œ (ì˜ˆ: /images/brands/Nike/ABC123.jpg)
        """
        try:
            # ì´ë¯¸ì§€ URL ê²€ì¦
            if not image_url or not image_url.startswith('http'):
                logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ URL: {image_url}")
                return image_url

            # ë¸Œëœë“œ ë””ë ‰í† ë¦¬ ìƒì„± (uploads/products/{ë¸Œëœë“œëª…})
            # Docker ë³¼ë¥¨ ë§ˆìš´íŠ¸: ./uploads -> /app/uploads
            brand_dir = Path(f"/app/uploads/products/{brand_name}")
            brand_dir.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ
            ext = '.png'  # ê¸°ë³¸ê°’ png
            if '.' in image_url:
                url_ext = image_url.split('?')[0].split('.')[-1].lower()
                if url_ext in ['jpg', 'jpeg', 'png', 'webp']:
                    ext = f'.{url_ext}'

            # íŒŒì¼ëª… ìƒì„± (ëª¨ë¸ë²ˆí˜¸ ê¸°ë°˜)
            safe_model = model_number.replace('/', '_').replace('\\', '_')
            file_name = f"{safe_model}{ext}"
            file_path = brand_dir / file_name

            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(image_url)

                if response.status_code == 200:
                    async with aiofiles.open(file_path, 'wb') as f:
                        await f.write(response.content)

                    # ìƒëŒ€ ê²½ë¡œ ë°˜í™˜ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©)
                    relative_path = f"/uploads/products/{brand_name}/{file_name}"
                    logger.info(f"âœ… ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {relative_path}")
                    return relative_path
                else:
                    logger.warning(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (HTTP {response.status_code}): {image_url}")
                    return image_url

        except Exception as e:
            logger.error(f"âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
            return image_url
